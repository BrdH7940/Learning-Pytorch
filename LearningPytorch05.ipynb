{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSmh+dHGDV4d8lsj1E8XeW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Going Modular\n","\n","Turn notebook into a series of different python scripts. For example:\n","\n","* data_setup.py - a file to prepare and download data if needed.\n","* engine.py - a file containing various training functions.\n","* model_builder.py or model.py - a file to create a PyTorch model.\n","* train.py - a file to leverage all other files and train a target PyTorch model.\n","* utils.py - a file dedicated to helpful utility functions.\n","\n","Why?\n","\n","* More reproducible and easier to run in larg scale projects.\n","\n","Example workflow:\n","* Start machine learning projects in Jupyter/Google Colab notebooks for quick experiment and visualization.\n","* When got something working, move the most useful pieces of code to python scripts.\n","\n","Note:\n","* Docstrings: To describe each of the functions/classes that will be put into scripts.\n","* Imports at the top of scripts."],"metadata":{"id":"cQFU5beej3uX"}},{"cell_type":"markdown","source":["# Get Data"],"metadata":{"id":"jp2u8fDRm51p"}},{"cell_type":"code","source":["import os\n","import torch\n","import requests, zipfile\n","\n","from pathlib import Path\n","from torch import nn\n","from torchvision import transforms"],"metadata":{"id":"qB-MidCAm71m","executionInfo":{"status":"ok","timestamp":1738549351545,"user_tz":-420,"elapsed":11245,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza-steak-sushi\"\n","\n","# If the image folder doens't exist, download\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists\")\n","else:\n","    print(f\"Didn't find {image_path}, creating one ...\")\n","    image_path.mkdir(parents =  True, exist_ok = True)\n","\n","# Download\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data ...\")\n","    f.write(request.content)\n","\n","# Unzip\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data ...\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5qaBfdWnRh5","executionInfo":{"status":"ok","timestamp":1738549554967,"user_tz":-420,"elapsed":3342,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"a06cbfa1-6b94-4f22-8048-f10e014878dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Didn't find data/pizza-steak-sushi, creating one ...\n","Downloading pizza, steak, sushi data ...\n","Unzipping pizza, steak, sushi data ...\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoaders\n","for image classification data\n","\"\"\"\n","import os\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    num_workers: int = NUM_WORKERS\n","):\n","    ''' Creates training and testing DataLoaders\n","\n","    Input: Training directory and testing directory path\n","    -> Pytorch Datasets\n","    -> Output: Pytorch DataLoaders\n","\n","    Args:\n","        train_dir: Path to training directory\n","        test_dir: Path to testing directory\n","        transform: Transforms to perform on training and testing data\n","        batch_size: Number of samples per batch in each of DataLoaders\n","        num_workers: Number of workers per DataLoader\n","\n","    Returns:\n","        (train_dataloader, test_dataloader, class_names)\n","    '''\n","\n","    # 1. Create datasets from original directory\n","    train_data = datasets.ImageFolder(train_dir, transform = transform)\n","    test_data = datasets.ImageFolder(test_dir, transform = transform)\n","\n","    # 2. Turn data into dataloaders\n","    train_dataloader = DataLoader(\n","        train_data,\n","        batch_size = batch_size,\n","        shuffle = True,\n","        num_workers = num_workers,\n","        pin_memory = True\n","    )\n","\n","    test_dataloader = DataLoader(\n","        test_data,\n","        batch_size = batch_size,\n","        shuffle = False,\n","        num_workers = num_workers,\n","        pin_memory = True\n","    )\n","\n","    return train_dataloader, test_dataloader, train_data.classes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vOn9Z5hoN8r","executionInfo":{"status":"ok","timestamp":1738553569067,"user_tz":-420,"elapsed":4,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"d2637be6-f1f6-4809-cc2c-3cc832213024"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/data_setup.py\n"]}]},{"cell_type":"markdown","source":["# Building Model"],"metadata":{"id":"8RO_idprrZAE"}},{"cell_type":"code","source":["%%writefile going_modular/model_builder.py\n","'''\n","Contains PyTorch code to instantiate a TinyVGG Model.\n","'''\n","import torch\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","    ''' Creates the TinyVGG architecture.\n","\n","    Args:\n","        input_shape: Number of input channels\n","        hidden_units: Number of hidden units between layers\n","        output_shape: Number of output units\n","    '''\n","    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(\n","              in_channels = input_shape,\n","              out_channels = hidden_units,\n","              kernel_size = 3,\n","              stride = 1,\n","              padding = 0\n","            ),\n","            nn.ReLU(),\n","            nn.Conv2d(\n","              in_channels = hidden_units,\n","              out_channels = hidden_units,\n","              kernel_size = 3,\n","              stride = 1,\n","              padding = 0\n","            ),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size = 2,\n","                stride = 2\n","            )\n","        )\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(\n","              in_channels = hidden_units,\n","              out_channels = hidden_units,\n","              kernel_size = 3,\n","              padding = 0\n","            ),\n","            nn.ReLU(),\n","            nn.Conv2d(\n","              in_channels = hidden_units,\n","              out_channels = hidden_units,\n","              kernel_size = 3,\n","              padding = 0\n","            ),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size = 2\n","            )\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(\n","                in_features = hidden_units * 13 * 13,\n","                out_features = output_shape\n","            )\n","        )\n","\n","    def forward(self, x: torch.Tensor):\n","        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dy3y_-hDrauh","executionInfo":{"status":"ok","timestamp":1738550682371,"user_tz":-420,"elapsed":497,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"d8cf9c90-bfcb-4a91-ff59-5f5899fef092"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/model_builder.py\n"]}]},{"cell_type":"markdown","source":["# Training and Testing"],"metadata":{"id":"Ez-JBIFDs6ID"}},{"cell_type":"code","source":["%%writefile going_modular/engine.py\n","'''\n","Contains functions for training and testing a pytorch model\n","'''\n","import torch\n","\n","from torch import nn\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(\n","    model: nn.Module,\n","    dataloader: torch.utils.data.DataLoader,\n","    loss_fn: nn.Module,\n","    optimizer: torch.optim.Optimizer,\n","    device: torch.device\n",") -> Tuple[float, float]:\n","    ''' Trains a PyTorch model for a single epoch.\n","\n","    Args:\n","        model: A PyTorch model to train\n","        dataloader: A DataLoader instance for the model to be trained on\n","        loss_fn: A PyTorch loss function to minimize\n","        optimizer: A PyTorch optimizer to help minimize the loss function\n","        device: A target device to compute on (e.g. \"cuda\" or \"cpu\")\n","\n","    Returns:\n","        (train_loss, train_accuracy).\n","    '''\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1. Forward-pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Calculate gradients for back prop\n","        loss.backward()\n","\n","        # 5. Updates parameters\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)\n","        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    train_loss /= len(dataloader)\n","    train_acc /= len(dataloader)\n","\n","    return train_loss, train_acc\n","\n","def test_step(\n","    model: nn.Module,\n","    dataloader: torch.utils.data.DataLoader,\n","    loss_fn: nn.Module,\n","    device: torch.device\n",") -> Tuple[float, float]:\n","    ''' Tests a PyTorch model for a single epoch.\n","\n","    Args:\n","        model: A PyTorch model to train\n","        dataloader: A DataLoader instance for the model to be trained on\n","        loss_fn: A PyTorch loss function to minimize\n","        device: A target device to compute on (e.g. \"cuda\" or \"cpu\")\n","\n","    Returns:\n","        (test_loss, test_accuracy).\n","    '''\n","    model.eval()\n","    test_loss, test_acc = 0, 0\n","\n","    with torch.inference_mode():\n","        for batch, (X, y) in enumerate(dataloader):\n","            X, y = X.to(device), y.to(device)\n","\n","            # 1. Forward-pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate loss\n","            loss = loss_fn(test_pred_logits, y)\n","            test_loss += loss.item()\n","\n","            # 3. Calculate accuracy\n","            test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim = 1), dim = 1)\n","            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    test_loss /= len(dataloader)\n","    test_acc /= len(dataloader)\n","\n","    return test_loss, test_acc\n","\n","def train(\n","    model: nn.Module,\n","    train_dataloader: torch.utils.data.DataLoader,\n","    test_dataloader: torch.utils.data.DataLoader,\n","    loss_fn: nn.Module,\n","    optimizer: torch.optim.Optimizer,\n","    epochs: int,\n","    device: torch.device\n",") -> Dict[str, List]:\n","    ''' Trains a PyTorch model.\n","\n","    Args:\n","        model: A PyTorch model to train\n","        train_dataloader: A DataLoader instance for the model to be trained on\n","        test_dataloader: A DataLoader instance for the model to be tested on\n","        loss_fn: A PyTorch loss function to minimize\n","        optimizer: A PyTorch optimizer to help minimize the loss function\n","        epochs: Number of epochs to train for\n","        device: A target device to compute on (e.g. \"cuda\" or \"cpu\")\n","\n","    Returns: History of training and testing loss and accuracy per epoch\n","        {train_loss: [...],\n","         train_acc: [...],\n","         test_loss: [...],\n","         test_acc: [...]}\n","    '''\n","    results = {\n","        \"train_loss\": [],\n","        \"train_acc\": [],\n","        \"test_loss\": [],\n","        \"test_acc\": []\n","    }\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(\n","            model = model,\n","            dataloader = train_dataloader,\n","            loss_fn = loss_fn,\n","            optimizer = optimizer,\n","            device = device\n","        )\n","        test_loss, test_acc = test_step(\n","            model = model,\n","            dataloader = test_dataloader,\n","            loss_fn = loss_fn,\n","            device = device\n","        )\n","\n","        print(\n","            f\"Epoch: {epoch+1} | \"\n","            f\"train_loss: {train_loss:.4f} | \"\n","            f\"train_acc: {train_acc:.4f} | \"\n","            f\"test_loss: {test_loss:.4f} | \"\n","            f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","    return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMLo9NBos8Rr","executionInfo":{"status":"ok","timestamp":1738553632429,"user_tz":-420,"elapsed":460,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"ff66cee4-5623-404c-f9f3-8d1082fada84"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/engine.py\n"]}]},{"cell_type":"markdown","source":["# Save and Load Model"],"metadata":{"id":"wuP77B7DzLRo"}},{"cell_type":"code","source":["%%writefile going_modular/utils.py\n","'''\n","Contains utility functions for PyTorch model training and saving.\n","'''\n","import torch\n","\n","from torch import nn\n","from pathlib import Path\n","\n","def save_model(\n","    model: nn.Module,\n","    target_dir: str,\n","    model_name: str\n","):\n","    ''' Saves a PyTorch model to a target directory\n","\n","    Args:\n","        model: A target PyTorch model to save\n","        target_dir: A directory for saving the model to\n","        model_name: A filename for the saved model\n","    '''\n","    # 1. Create target directory\n","    target_dir_path = Path(target_dir)\n","    target_dir_path.mkdir(parents = True, exist_ok = True)\n","\n","    # 2. Create model save path\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should and with '.pt' or '.pth'\"\n","    model_save_path = target_dir_path / model_name\n","\n","    # 3. Save the model with state_dict()\n","    print(f\"[INFO] Saving model to: {model_save_path}\")\n","    torch.save(\n","        obj = model.state_dict(),\n","        f = model_save_path\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRlAMcNqzN1W","executionInfo":{"status":"ok","timestamp":1738552956068,"user_tz":-420,"elapsed":468,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"a6a89cf5-f644-4638-b0fb-e34aec2568e5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/utils.py\n"]}]},{"cell_type":"markdown","source":["# Combine Things\n","\n","Combine all the python scripts created above into a ```train.py``` file so that we can train a PyTorch model using a single line of command."],"metadata":{"id":"YaEBEqGI1XXn"}},{"cell_type":"code","source":["%%writefile going_modular/train.py\n","'''\n","Trains a PyTorch image classification model using device-agnostic code\n","'''\n","import os\n","import torch\n","import data_setup, engine, model_builder, utils\n","from torch import nn\n","from torchvision import transforms\n","\n","# Setup hyperparams\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 32\n","HIDDEN_UNITS = 10\n","LEARNING_RATE = 0.001\n","\n","# Setup directories (For getting data)\n","train_dir = \"data/pizza-steak-sushi/train\"\n","test_dir = \"data/pizza-steak-sushi/test\"\n","\n","# Setup device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","# Create DataLoaders (data_setup.py)\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir = train_dir,\n","    test_dir = test_dir,\n","    transform = data_transform,\n","    batch_size = BATCH_SIZE\n",")\n","\n","# Create Model (model_builder.py)\n","model = model_builder.TinyVGG(\n","    input_shape = 3,\n","    hidden_units = HIDDEN_UNITS,\n","    output_shape = len(class_names)\n",").to(device)\n","\n","# Setup loss function and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(\n","    model.parameters(),\n","    lr = LEARNING_RATE\n",")\n","\n","# Training (engine.py)\n","engine.train(\n","    model = model,\n","    train_dataloader = train_dataloader,\n","    test_dataloader = test_dataloader,\n","    loss_fn = loss_fn,\n","    optimizer = optimizer,\n","    epochs = NUM_EPOCHS,\n","    device = device\n",")\n","\n","# Save model (utils.py)\n","utils.save_model(\n","    model = model,\n","    target_dir = \"models\",\n","    model_name = \"05_going_modular_script_mode_tinyvgg_model.pth\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbAd7XTL1aaX","executionInfo":{"status":"ok","timestamp":1738553605417,"user_tz":-420,"elapsed":665,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"dec6fa16-f67e-4234-ada5-4a664983f794"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/train.py\n"]}]},{"cell_type":"code","source":["!python going_modular/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHgD_7ox2K9O","executionInfo":{"status":"ok","timestamp":1738553655316,"user_tz":-420,"elapsed":15274,"user":{"displayName":"Hui Lee Min","userId":"18192544667195824196"}},"outputId":"3928f084-aa3c-4342-af02-a89a1c6fd89e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["  0% 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1116 | train_acc: 0.2656 | test_loss: 1.1063 | test_acc: 0.2604\n"," 20% 1/5 [00:03<00:12,  3.12s/it]Epoch: 2 | train_loss: 1.0946 | train_acc: 0.4258 | test_loss: 1.0943 | test_acc: 0.2604\n"," 40% 2/5 [00:05<00:08,  2.67s/it]Epoch: 3 | train_loss: 1.0936 | train_acc: 0.4258 | test_loss: 1.0934 | test_acc: 0.2604\n"," 60% 3/5 [00:07<00:04,  2.22s/it]Epoch: 4 | train_loss: 1.0965 | train_acc: 0.3047 | test_loss: 1.0888 | test_acc: 0.2604\n"," 80% 4/5 [00:08<00:01,  2.00s/it]Epoch: 5 | train_loss: 1.0897 | train_acc: 0.3047 | test_loss: 1.0757 | test_acc: 0.2604\n","100% 5/5 [00:10<00:00,  2.10s/it]\n","[INFO] Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_4ssdbKU3Eyu"},"execution_count":null,"outputs":[]}]}